{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cg-hP0itZxmX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2520 images belonging to 3 classes.\n",
      "Found 2520 images belonging to 3 classes.\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1842 - acc: 0.9353\n",
      "Epoch 00001: val_loss improved from inf to 0.00239, saving model to my_checkpoint_rps2.ckpt\n",
      "79/79 [==============================] - 116s 1s/step - loss: 0.1842 - acc: 0.9353 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0132 - acc: 0.9948\n",
      "Epoch 00002: val_loss improved from 0.00239 to 0.00007, saving model to my_checkpoint_rps2.ckpt\n",
      "79/79 [==============================] - 115s 1s/step - loss: 0.0132 - acc: 0.9948 - val_loss: 7.0918e-05 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9968\n",
      "Epoch 00003: val_loss did not improve from 0.00007\n",
      "79/79 [==============================] - 115s 1s/step - loss: 0.0083 - acc: 0.9968 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0091 - acc: 0.9976\n",
      "Epoch 00004: val_loss did not improve from 0.00007\n",
      "79/79 [==============================] - 114s 1s/step - loss: 0.0091 - acc: 0.9976 - val_loss: 5.6506e-04 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0016 - acc: 0.9992\n",
      "Epoch 00005: val_loss did not improve from 0.00007\n",
      "79/79 [==============================] - 114s 1s/step - loss: 0.0016 - acc: 0.9992 - val_loss: 1.7648e-04 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0236 - acc: 0.9909\n",
      "Epoch 00006: val_loss did not improve from 0.00007\n",
      "79/79 [==============================] - 115s 1s/step - loss: 0.0236 - acc: 0.9909 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0147 - acc: 0.9944\n",
      "Epoch 00007: val_loss improved from 0.00007 to 0.00003, saving model to my_checkpoint_rps2.ckpt\n",
      "79/79 [==============================] - 115s 1s/step - loss: 0.0147 - acc: 0.9944 - val_loss: 3.1675e-05 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 3.6183e-04 - acc: 1.0000\n",
      "Epoch 00008: val_loss improved from 0.00003 to 0.00002, saving model to my_checkpoint_rps2.ckpt\n",
      "79/79 [==============================] - 116s 1s/step - loss: 3.6183e-04 - acc: 1.0000 - val_loss: 2.2486e-05 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9988\n",
      "Epoch 00009: val_loss improved from 0.00002 to 0.00001, saving model to my_checkpoint_rps2.ckpt\n",
      "79/79 [==============================] - 114s 1s/step - loss: 0.0034 - acc: 0.9988 - val_loss: 1.0236e-05 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0115 - acc: 0.9960\n",
      "Epoch 00010: val_loss did not improve from 0.00001\n",
      "79/79 [==============================] - 114s 1s/step - loss: 0.0115 - acc: 0.9960 - val_loss: 0.0026 - val_acc: 0.9996\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9980\n",
      "Epoch 00011: val_loss did not improve from 0.00001\n",
      "79/79 [==============================] - 115s 1s/step - loss: 0.0056 - acc: 0.9980 - val_loss: 1.7302e-05 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.9980\n",
      "Epoch 00012: val_loss improved from 0.00001 to 0.00000, saving model to my_checkpoint_rps2.ckpt\n",
      "79/79 [==============================] - 116s 1s/step - loss: 0.0067 - acc: 0.9980 - val_loss: 7.0533e-07 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0040 - acc: 0.9980\n",
      "Epoch 00013: val_loss did not improve from 0.00000\n",
      "79/79 [==============================] - 116s 1s/step - loss: 0.0040 - acc: 0.9980 - val_loss: 5.2740e-05 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0136 - acc: 0.9960\n",
      "Epoch 00014: val_loss did not improve from 0.00000\n",
      "79/79 [==============================] - 116s 1s/step - loss: 0.0136 - acc: 0.9960 - val_loss: 1.3874e-06 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0892e-04 - acc: 1.0000\n",
      "Epoch 00015: val_loss improved from 0.00000 to 0.00000, saving model to my_checkpoint_rps2.ckpt\n",
      "79/79 [==============================] - 115s 1s/step - loss: 1.0892e-04 - acc: 1.0000 - val_loss: 5.1666e-07 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0368 - acc: 0.9873\n",
      "Epoch 00016: val_loss did not improve from 0.00000\n",
      "79/79 [==============================] - 114s 1s/step - loss: 0.0368 - acc: 0.9873 - val_loss: 5.5320e-04 - val_acc: 0.9996\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0114 - acc: 0.9968\n",
      "Epoch 00017: val_loss did not improve from 0.00000\n",
      "79/79 [==============================] - 116s 1s/step - loss: 0.0114 - acc: 0.9968 - val_loss: 1.0261e-06 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.7258e-04 - acc: 1.0000\n",
      "Epoch 00018: val_loss did not improve from 0.00000\n",
      "79/79 [==============================] - 115s 1s/step - loss: 2.7258e-04 - acc: 1.0000 - val_loss: 4.5413e-06 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9984\n",
      "Epoch 00019: val_loss did not improve from 0.00000\n",
      "79/79 [==============================] - 114s 1s/step - loss: 0.0034 - acc: 0.9984 - val_loss: 1.9205e-06 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1579e-04 - acc: 1.0000\n",
      "Epoch 00020: val_loss improved from 0.00000 to 0.00000, saving model to my_checkpoint_rps2.ckpt\n",
      "79/79 [==============================] - 115s 1s/step - loss: 1.1579e-04 - acc: 1.0000 - val_loss: 3.4675e-08 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# There are 5 questions in this test with increasing difficulty from 1-5\n",
    "# Please note that the weight of the grade for the question is relative\n",
    "# to its difficulty. So your Category 1 question will score much less\n",
    "# than your Category 5 question.\n",
    "# ======================================================================\n",
    "#\n",
    "# Computer Vision with CNNs\n",
    "#\n",
    "# For this task you will build a classifier for Rock-Paper-Scissors \n",
    "# based on the rps dataset.\n",
    "#\n",
    "# IMPORTANT: Your final layer should be as shown, do not change the\n",
    "# provided code, or the tests may fail\n",
    "#\n",
    "# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
    "# So ensure that your input layer is designed accordingly, or the tests\n",
    "# may fail. \n",
    "#\n",
    "# NOTE THAT THIS IS UNLABELLED DATA. \n",
    "# You can use the ImageDataGenerator to automatically label it\n",
    "# and we have provided some starter code.\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "def solution_model():\n",
    "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
    "    urllib.request.urlretrieve(url, 'rps.zip')\n",
    "    local_zip = 'rps.zip'\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    zip_ref.extractall('./tmp/')\n",
    "    zip_ref.close()\n",
    "\n",
    "\n",
    "    TRAINING_DIR = \"./tmp/rps/\"\n",
    "    training_datagen = ImageDataGenerator(\n",
    "    # YOUR CODE HERE\n",
    "    rescale=1/255.,\n",
    "    shear_range = 0.2, \n",
    "    zoom_range = 0.2, \n",
    "    horizontal_flip = True\n",
    "    )\n",
    "\n",
    "#     train_generator = # YOUR CODE HERE\n",
    "    train_generator = training_datagen.flow_from_directory(\n",
    "        './tmp/rps/',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode = 'categorical'\n",
    "    )\n",
    "    \n",
    "    valid_datagen = ImageDataGenerator(\n",
    "        rescale=1/255.,\n",
    "     )\n",
    "\n",
    "    valid_generator = valid_datagen.flow_from_directory(\n",
    "            TRAINING_DIR,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=32,\n",
    "            class_mode = 'categorical'\n",
    "     )\n",
    "    conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "    conv_base.trainable = False\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        conv_base,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),                                       \n",
    "\n",
    "    # YOUR CODE HERE, BUT END WITH A 3 Neuron Dense, activated by softmax\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                 metrics=['acc'])\n",
    "    checkpoint_path = \"my_checkpoint_rps2.ckpt\"\n",
    "    checkpoint = ModelCheckpoint(filepath= checkpoint_path, save_weights_only=True,\n",
    "                                save_best_only=True, monitor='val_loss', verbose=1)\n",
    "    model.fit(train_generator, validation_data=(valid_generator), epochs=20\n",
    "             ,callbacks=[checkpoint])\n",
    "    model.load_weights(checkpoint_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Note that you'll need to save your model as a .h5 like this\n",
    "# This .h5 will be uploaded to the testing infrastructure\n",
    "# and a score will be returned to you\n",
    "if __name__ == '__main__':\n",
    "    model = solution_model()\n",
    "    model.save(\"cat3_rps2_vgg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CSlkwvLvy_Q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TF3-rps (문제)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
