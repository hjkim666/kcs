{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cg-hP0itZxmX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2520 images belonging to 3 classes.\n",
      "Found 372 images belonging to 3 classes.\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7262 - acc: 0.6437\n",
      "Epoch 00001: val_loss improved from inf to 0.47547, saving model to my_checkpoint_rps1.ckpt\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 0.7262 - acc: 0.6437 - val_loss: 0.4755 - val_acc: 0.8065\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1559 - acc: 0.9460\n",
      "Epoch 00002: val_loss did not improve from 0.47547\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 0.1559 - acc: 0.9460 - val_loss: 0.4970 - val_acc: 0.8441\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0439 - acc: 0.9861\n",
      "Epoch 00003: val_loss improved from 0.47547 to 0.26604, saving model to my_checkpoint_rps1.ckpt\n",
      "79/79 [==============================] - 35s 444ms/step - loss: 0.0439 - acc: 0.9861 - val_loss: 0.2660 - val_acc: 0.9167\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0270 - acc: 0.9913\n",
      "Epoch 00004: val_loss improved from 0.26604 to 0.11537, saving model to my_checkpoint_rps1.ckpt\n",
      "79/79 [==============================] - 34s 434ms/step - loss: 0.0270 - acc: 0.9913 - val_loss: 0.1154 - val_acc: 0.9489\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0309 - acc: 0.9913\n",
      "Epoch 00005: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 0.0309 - acc: 0.9913 - val_loss: 0.3562 - val_acc: 0.8871\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9956\n",
      "Epoch 00006: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 0.0137 - acc: 0.9956 - val_loss: 0.1453 - val_acc: 0.9462\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0166 - acc: 0.9940\n",
      "Epoch 00007: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 0.0166 - acc: 0.9940 - val_loss: 0.1730 - val_acc: 0.9274\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0143 - acc: 0.9948\n",
      "Epoch 00008: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 433ms/step - loss: 0.0143 - acc: 0.9948 - val_loss: 0.2384 - val_acc: 0.9328\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9960\n",
      "Epoch 00009: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 0.0075 - acc: 0.9960 - val_loss: 0.8405 - val_acc: 0.8844\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0115 - acc: 0.9972\n",
      "Epoch 00010: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.2307 - val_acc: 0.9220\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0429 - acc: 0.9881\n",
      "Epoch 00011: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 35s 439ms/step - loss: 0.0429 - acc: 0.9881 - val_loss: 0.4911 - val_acc: 0.8199\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0205 - acc: 0.9948\n",
      "Epoch 00012: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 432ms/step - loss: 0.0205 - acc: 0.9948 - val_loss: 0.5798 - val_acc: 0.9032\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0079 - acc: 0.9972\n",
      "Epoch 00013: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.5564 - val_acc: 0.8817\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 00014: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.3535 - val_acc: 0.9113\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9984\n",
      "Epoch 00015: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 0.0083 - acc: 0.9984 - val_loss: 0.1641 - val_acc: 0.9435\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0105 - acc: 0.9964\n",
      "Epoch 00016: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.1633 - val_acc: 0.9597\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0095 - acc: 0.9984\n",
      "Epoch 00017: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 35s 437ms/step - loss: 0.0095 - acc: 0.9984 - val_loss: 0.2260 - val_acc: 0.9543\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0015 - acc: 0.9992\n",
      "Epoch 00018: val_loss did not improve from 0.11537\n",
      "79/79 [==============================] - 34s 435ms/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.3311 - val_acc: 0.9274\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0048 - acc: 0.9984\n",
      "Epoch 00019: val_loss improved from 0.11537 to 0.05951, saving model to my_checkpoint_rps1.ckpt\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0595 - val_acc: 0.9731\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0025 - acc: 0.9988\n",
      "Epoch 00020: val_loss did not improve from 0.05951\n",
      "79/79 [==============================] - 35s 444ms/step - loss: 0.0025 - acc: 0.9988 - val_loss: 0.4533 - val_acc: 0.9194\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# There are 5 questions in this test with increasing difficulty from 1-5\n",
    "# Please note that the weight of the grade for the question is relative\n",
    "# to its difficulty. So your Category 1 question will score much less\n",
    "# than your Category 5 question.\n",
    "# ======================================================================\n",
    "#\n",
    "# Computer Vision with CNNs\n",
    "#\n",
    "# For this task you will build a classifier for Rock-Paper-Scissors \n",
    "# based on the rps dataset.\n",
    "#\n",
    "# IMPORTANT: Your final layer should be as shown, do not change the\n",
    "# provided code, or the tests may fail\n",
    "#\n",
    "# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
    "# So ensure that your input layer is designed accordingly, or the tests\n",
    "# may fail. \n",
    "#\n",
    "# NOTE THAT THIS IS UNLABELLED DATA. \n",
    "# You can use the ImageDataGenerator to automatically label it\n",
    "# and we have provided some starter code.\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def solution_model():\n",
    "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
    "    urllib.request.urlretrieve(url, 'rps.zip')\n",
    "    local_zip = 'rps.zip'\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    zip_ref.extractall('./tmp/')\n",
    "    zip_ref.close()\n",
    "\n",
    "    #코드외에 새로 추가한 valid 데이터 셋 \n",
    "    url2 = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip'\n",
    "    urllib.request.urlretrieve(url2, 'rps-test-set.zip')\n",
    "    local_zip2 = 'rps-test-set.zip'\n",
    "    zip_ref2 = zipfile.ZipFile(local_zip2, 'r')\n",
    "    zip_ref2.extractall('./tmp/')\n",
    "    zip_ref2.close()\n",
    "\n",
    "    TRAINING_DIR = \"./tmp/rps/\"\n",
    "    VALID_DIR = \"./tmp/rps-test-set/\"\n",
    "    training_datagen = ImageDataGenerator(\n",
    "    # YOUR CODE HERE\n",
    "    rescale=1/255.,\n",
    "    shear_range = 0.2, \n",
    "    zoom_range = 0.2, \n",
    "    horizontal_flip = True\n",
    "    )\n",
    "\n",
    "#     train_generator = # YOUR CODE HERE\n",
    "    train_generator = training_datagen.flow_from_directory(\n",
    "        TRAINING_DIR,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode = 'categorical'\n",
    "    )\n",
    "    valid_datagen = ImageDataGenerator(\n",
    "        # YOUR CODE HERE\n",
    "        rescale=1/255.\n",
    "        )\n",
    "\n",
    "    valid_generator = valid_datagen.flow_from_directory(\n",
    "            VALID_DIR,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=32,\n",
    "            class_mode = 'categorical'\n",
    "     )\n",
    "    \n",
    "#     print(train_generator.next())\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64,(3,3), input_shape=(150,150,3), activation='relu'), \n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64,(3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "        tf.keras.layers.Conv2D(128,(3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "        tf.keras.layers.Conv2D(128,(3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),                                       \n",
    "\n",
    "    # YOUR CODE HERE, BUT END WITH A 3 Neuron Dense, activated by softmax\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                 metrics=['acc'])\n",
    "    checkpoint_path = \"my_checkpoint_rps1.ckpt\"\n",
    "    checkpoint = ModelCheckpoint(filepath= checkpoint_path, save_weights_only=True,\n",
    "                                save_best_only=True, monitor='val_loss', verbose=1)\n",
    "    model.fit(train_generator, validation_data=(valid_generator), epochs=20\n",
    "             ,callbacks=[checkpoint])\n",
    "    model.load_weights(checkpoint_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Note that you'll need to save your model as a .h5 like this\n",
    "# This .h5 will be uploaded to the testing infrastructure\n",
    "# and a score will be returned to you\n",
    "if __name__ == '__main__':\n",
    "    model = solution_model()\n",
    "    model.save(\"cat3_rps1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CSlkwvLvy_Q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TF3-rps (문제)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
