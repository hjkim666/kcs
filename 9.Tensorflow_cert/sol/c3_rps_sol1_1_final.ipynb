{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C3_rps_기출문제_sol1_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg-hP0itZxmX"
      },
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this test with increasing difficulty from 1-5\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score much less\n",
        "# than your Category 5 question.\n",
        "# ======================================================================\n",
        "#\n",
        "# Computer Vision with CNNs\n",
        "#\n",
        "# For this task you will build a classifier for Rock-Paper-Scissors \n",
        "# based on the rps dataset.\n",
        "#\n",
        "# IMPORTANT: Your final layer should be as shown, do not change the\n",
        "# provided code, or the tests may fail\n",
        "#\n",
        "# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
        "# So ensure that your input layer is designed accordingly, or the tests\n",
        "# may fail. \n",
        "#\n",
        "# NOTE THAT THIS IS UNLABELLED DATA. \n",
        "# You can use the ImageDataGenerator to automatically label it\n",
        "# and we have provided some starter code.\n",
        "\n",
        "\n",
        "# 주어진문제\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def solution_model():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
        "    urllib.request.urlretrieve(url, 'rps.zip')\n",
        "    local_zip = 'rps.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/')\n",
        "    zip_ref.close()\n",
        "\n",
        "\n",
        "    TRAINING_DIR = \"tmp/rps/\"\n",
        "    training_datagen = ImageDataGenerator(\n",
        "    # YOUR CODE HERE)\n",
        "\n",
        "\n",
        "\n",
        "    train_generator = # YOUR CODE HERE\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "                                        \n",
        "\n",
        "\n",
        "    # YOUR CODE HERE, BUT END WITH A 3 Neuron Dense, activated by softmax\n",
        "        tf.keras.layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this\n",
        "# This .h5 will be uploaded to the testing infrastructure\n",
        "# and a score will be returned to you\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"TF3-rps.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CSlkwvLvy_Q"
      },
      "source": [
        "# 데이터를 다운로드 받기 \r\n",
        "import urllib.request\r\n",
        "import zipfile\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\r\n",
        "urllib.request.urlretrieve(url, 'rps.zip')\r\n",
        "local_zip = 'rps.zip'\r\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n",
        "zip_ref.extractall('./tmp/')\r\n",
        "zip_ref.close()\r\n",
        "\r\n",
        "###  train 데이터셋을 8:2로  train:valid로 나누기 \r\n",
        "import os \r\n",
        "import glob \r\n",
        "import random \r\n",
        "import shutil \r\n",
        "import numpy as np \r\n",
        "ROOT_DIR = './tmp/'\r\n",
        "TRAINING_DIR = \"./tmp/rps/\"\r\n",
        "\r\n",
        "\r\n",
        "#폴더 없으면 만드는 함수 \r\n",
        "def createfolder(directory):\r\n",
        "    if not os.path.exists(directory):\r\n",
        "        os.makedirs(directory)\r\n",
        "\r\n",
        "#상위폴더 만들기 \r\n",
        "createfolder(ROOT_DIR+'rps_train0')\r\n",
        "createfolder(ROOT_DIR+'rps_valid0')\r\n",
        "\r\n",
        "folders = ['paper', 'rock', 'scissors']\r\n",
        "\r\n",
        "#하위폴더만들기 \r\n",
        "for f in folders: \r\n",
        "    createfolder(ROOT_DIR+'rps_train0/'+f)\r\n",
        "    createfolder(ROOT_DIR+'rps_valid0/'+f)\r\n",
        "\r\n",
        "# 각 폴더에 파일 카피 (랜덤하게 뽑은 인덱스를 이용)\r\n",
        "def copy_files(folder):\r\n",
        "    files = glob.glob(TRAINING_DIR + folder + '/*.*')\r\n",
        "    ratio = 0.2 \r\n",
        "    rand_index = np.random.choice(len(files), int(len(files)*ratio), replace=False)\r\n",
        "\r\n",
        "    for i, f in enumerate(files):\r\n",
        "        fname = os.path.basename(f)\r\n",
        "        if i in rand_index:\r\n",
        "            print('{} is copying to train folder'.format(fname))\r\n",
        "            shutil.copy2(os.path.join(TRAINING_DIR, folder, fname), os.path.join(ROOT_DIR, 'rps_valid0', folder))\r\n",
        "        else:\r\n",
        "            print('{} is copying to valid folder'.format(fname))\r\n",
        "            shutil.copy2(os.path.join(TRAINING_DIR, folder, fname),  os.path.join(ROOT_DIR,'rps_train0', folder))\r\n",
        "\r\n",
        "# 각 폴더마다 순회하며 카피 \r\n",
        "for a in folders: \r\n",
        "    copy_files(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3u8Gt16jKwR",
        "outputId": "53c31a57-0d35-4e63-bfed-2fa25f85d344"
      },
      "source": [
        "# 다시풀기 \r\n",
        "def solution_model():\r\n",
        "    # url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\r\n",
        "    # urllib.request.urlretrieve(url, 'rps.zip')\r\n",
        "    # local_zip = 'rps.zip'\r\n",
        "    # zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n",
        "    # zip_ref.extractall('./tmp/')\r\n",
        "    # zip_ref.close()\r\n",
        "\r\n",
        "    TRAINING_DIR = \"./tmp/rps_train0/\"\r\n",
        "    VALID_DIR = \"./tmp/rps_valid0\"\r\n",
        "    training_datagen = ImageDataGenerator(\r\n",
        "    # YOUR CODE HERE)\r\n",
        "      rescale = 1/255., \r\n",
        "      zoom_range = 0.2, \r\n",
        "      width_shift_range = 0.1, \r\n",
        "      height_shift_range = 0.1 \r\n",
        "    )\r\n",
        "\r\n",
        "    train_generator =training_datagen.flow_from_directory(\r\n",
        "        TRAINING_DIR, \r\n",
        "        target_size=(150,150),\r\n",
        "        batch_size=32,\r\n",
        "        class_mode = 'categorical'\r\n",
        "    )\r\n",
        "\r\n",
        "    valid_datagen = ImageDataGenerator(\r\n",
        "        rescale = 1/255.\r\n",
        "    )\r\n",
        "\r\n",
        "    valid_generator = valid_datagen.flow_from_directory(\r\n",
        "        VALID_DIR, \r\n",
        "        target_size=(150,150),\r\n",
        "        batch_size=32,\r\n",
        "        class_mode = 'categorical'\r\n",
        "    )\r\n",
        "\r\n",
        "    model = tf.keras.models.Sequential([\r\n",
        "          Conv2D(32, (3,3), input_shape=(150,150,3), activation='relu'),                             \r\n",
        "          MaxPool2D(2,2),\r\n",
        "          Conv2D(64, (3,3), activation='relu'),\r\n",
        "          MaxPool2D(2,2),\r\n",
        "          Conv2D(128, (3,3), activation='relu'),\r\n",
        "          MaxPool2D(2,2),\r\n",
        "          Flatten(),\r\n",
        "          Dropout(0.5), \r\n",
        "          Dense(256, activation='relu'),\r\n",
        "          Dense(128, activation='relu'),\r\n",
        "    # YOUR CODE HERE, BUT END WITH A 3 Neuron Dense, activated by softmax\r\n",
        "        tf.keras.layers.Dense(3, activation='softmax')\r\n",
        "    ])\r\n",
        "\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\r\n",
        "    checkpoint_path = 'rps_checkpoint1-1.ckpt'\r\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_path,\r\n",
        "                              save_weights_only = True, \r\n",
        "                              save_best_only = True, \r\n",
        "                              monitor='val_loss',\r\n",
        "                              verbose=1)\r\n",
        "    model.fit(train_generator, validation_data=valid_generator, epochs=20, \r\n",
        "            callbacks=[checkpoint]) \r\n",
        "    model.load_weights(checkpoint_path)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Note that you'll need to save your model as a .h5 like this\r\n",
        "# This .h5 will be uploaded to the testing infrastructure\r\n",
        "# and a score will be returned to you\r\n",
        "if __name__ == '__main__':\r\n",
        "    model = solution_model()\r\n",
        "    model.save(\"TF3-rps1-1.h5\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2016 images belonging to 3 classes.\n",
            "Found 504 images belonging to 3 classes.\n",
            "Epoch 1/20\n",
            "63/63 [==============================] - 16s 250ms/step - loss: 1.0811 - acc: 0.4489 - val_loss: 0.1480 - val_acc: 0.9702\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.14796, saving model to rps_checkpoint1-1.ckpt\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 16s 246ms/step - loss: 0.3371 - acc: 0.8793 - val_loss: 0.0244 - val_acc: 0.9940\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.14796 to 0.02442, saving model to rps_checkpoint1-1.ckpt\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 16s 249ms/step - loss: 0.1506 - acc: 0.9505 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.02442 to 0.00471, saving model to rps_checkpoint1-1.ckpt\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 16s 248ms/step - loss: 0.0813 - acc: 0.9695 - val_loss: 0.0305 - val_acc: 0.9881\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00471\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 16s 247ms/step - loss: 0.0586 - acc: 0.9827 - val_loss: 0.0025 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00471 to 0.00248, saving model to rps_checkpoint1-1.ckpt\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 15s 246ms/step - loss: 0.0391 - acc: 0.9850 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.00248\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 16s 247ms/step - loss: 0.0530 - acc: 0.9802 - val_loss: 0.0032 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00248\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 16s 248ms/step - loss: 0.0675 - acc: 0.9793 - val_loss: 0.0085 - val_acc: 0.9980\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00248\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 16s 249ms/step - loss: 0.0234 - acc: 0.9912 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00248 to 0.00154, saving model to rps_checkpoint1-1.ckpt\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 16s 249ms/step - loss: 0.0273 - acc: 0.9906 - val_loss: 3.2813e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00154 to 0.00033, saving model to rps_checkpoint1-1.ckpt\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 16s 247ms/step - loss: 0.0223 - acc: 0.9913 - val_loss: 2.0119e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00033 to 0.00020, saving model to rps_checkpoint1-1.ckpt\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 16s 248ms/step - loss: 0.0217 - acc: 0.9909 - val_loss: 5.2137e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00020\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 16s 247ms/step - loss: 0.0146 - acc: 0.9943 - val_loss: 7.0116e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00020 to 0.00007, saving model to rps_checkpoint1-1.ckpt\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 16s 253ms/step - loss: 0.0282 - acc: 0.9896 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00007\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 16s 250ms/step - loss: 0.0218 - acc: 0.9920 - val_loss: 8.3679e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00007\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 16s 246ms/step - loss: 0.0251 - acc: 0.9932 - val_loss: 2.2358e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00007\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 15s 246ms/step - loss: 0.0142 - acc: 0.9963 - val_loss: 4.4821e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00007 to 0.00004, saving model to rps_checkpoint1-1.ckpt\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 16s 248ms/step - loss: 0.0110 - acc: 0.9960 - val_loss: 2.6078e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00004 to 0.00003, saving model to rps_checkpoint1-1.ckpt\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 16s 253ms/step - loss: 0.0084 - acc: 0.9966 - val_loss: 0.0077 - val_acc: 0.9960\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00003\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 16s 254ms/step - loss: 0.0174 - acc: 0.9924 - val_loss: 4.3931e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00003\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}